# Default values for bank-app-logstash
# This is a wrapper chart for the official Logstash Helm chart

logstash:
  # Number of replicas
  replicas: 1

  # Resources
  resources:
    requests:
      cpu: "500m"
      memory: "1Gi"
    limits:
      cpu: "1000m"
      memory: "2Gi"

  # JVM heap size
  logstashJavaOpts: "-Xmx512m -Xms512m"

  # Service configuration
  service:
    type: ClusterIP
    ports:
      - name: beats
        port: 5044
        protocol: TCP
        targetPort: 5044

  # Persistence - not needed for Logstash as it's stateless
  persistence:
    enabled: false

  # Logstash pipeline configuration
  logstashPipeline:
    logstash.conf: |
      input {
        kafka {
          bootstrap_servers => "${KAFKA_BOOTSTRAP_SERVERS:bank-app-kafka:9092}"
          topics => ["bank.logs"]
          codec => json
          group_id => "logstash-consumer-group"
          consumer_threads => 3
          decorate_events => true
          auto_offset_reset => "earliest"
        }
      }

      filter {
        # Parse JSON if not already parsed
        if [message] =~ /^\{.*\}$/ {
          json {
            source => "message"
            skip_on_invalid_json => true
          }
        }

        # Add timestamp field
        if [timestamp] {
          date {
            match => ["timestamp", "ISO8601", "yyyy-MM-dd'T'HH:mm:ss.SSS'Z'", "yyyy-MM-dd HH:mm:ss.SSS"]
            target => "@timestamp"
          }
        }

        # Mask sensitive data
        mutate {
          # Mask passwords
          gsub => [
            "message", "password=[^&\s]+", "password=***",
            "message", "\"password\":\s*\"[^\"]+\"", "\"password\":\"***\"",
            # Mask tokens
            "message", "token=[^&\s]+", "token=***",
            "message", "\"token\":\s*\"[^\"]+\"", "\"token\":\"***\"",
            # Mask authorization headers
            "message", "Authorization:\s*[^\s]+", "Authorization: ***",
            "message", "\"Authorization\":\s*\"[^\"]+\"", "\"Authorization\":\"***\""
          ]
        }

        # Add metadata
        mutate {
          add_field => {
            "[@metadata][index_prefix]" => "bank-logs"
          }
        }

        # Parse application name from Kafka metadata
        if [@metadata][kafka][topic] {
          mutate {
            add_field => { "kafka_topic" => "%{[@metadata][kafka][topic]}" }
          }
        }

        # Remove unnecessary fields
        mutate {
          remove_field => ["@version", "host"]
        }
      }

      output {
        elasticsearch {
          hosts => ["${ELASTICSEARCH_HOST:bank-app-elasticsearch-elasticsearch:9200}"]
          index => "bank-logs-%{+YYYY.MM.dd}"
          # For production with authentication:
          # user => "${ELASTICSEARCH_USER:elastic}"
          # password => "${ELASTICSEARCH_PASSWORD:changeme}"
          # ssl => true
          # cacert => "/usr/share/logstash/config/certs/ca.crt"
        }

        # Uncomment for debugging
        # stdout {
        #   codec => rubydebug
        # }
      }

  # Environment variables
  extraEnvs:
    - name: KAFKA_BOOTSTRAP_SERVERS
      value: "bank-app-kafka:9092"
    - name: ELASTICSEARCH_HOST
      value: "bank-app-elasticsearch-elasticsearch:9200"
    # For production with Elasticsearch auth:
    # - name: ELASTICSEARCH_USER
    #   valueFrom:
    #     secretKeyRef:
    #       name: elasticsearch-credentials
    #       key: username
    # - name: ELASTICSEARCH_PASSWORD
    #   valueFrom:
    #     secretKeyRef:
    #       name: elasticsearch-credentials
    #       key: password

  # Probes
  livenessProbe:
    httpGet:
      path: /
      port: 9600
    initialDelaySeconds: 60
    periodSeconds: 10

  readinessProbe:
    httpGet:
      path: /
      port: 9600
    initialDelaySeconds: 30
    periodSeconds: 5
